{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c0b248-d13f-48b9-9ac9-c5553d92a7e7",
   "metadata": {},
   "source": [
    "# Binaural Sonification of Magnetometer Data\n",
    "The purpose of this notebook is to generate binaural audio displays of data from ground magnetometers and THEMIS satellites. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e20e0d-931c-4a93-92ed-bf39c679ae42",
   "metadata": {},
   "source": [
    "### Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5fe8a8b-da15-4f2c-89ae-d79cb9ce0780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71ca2eb-fc23-4a2b-bf59-2a6213a38ea3",
   "metadata": {},
   "source": [
    "## Set parameters\n",
    "First, we should establish the datetime range, stations, and cadence of the data that we want to examine with this approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b0d3f-7d52-4496-8775-d0e9826a75eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b519fdc-5bbd-4921-ab1d-b09f33857802",
   "metadata": {},
   "source": [
    "## Pull data of interest\n",
    "Next, we pull the data of interest into pandas dataframes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cc186f-3318-4e98-a7ae-6f0151c7e803",
   "metadata": {},
   "source": [
    "## Sonify data\n",
    "There are two pieces of information we need to sort out in this step: what each sound source sounds like, and where it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e78f6d-c6f8-4cc6-ab07-d36eaeeb2141",
   "metadata": {},
   "source": [
    "### Convert data to sound\n",
    "Now we sonify the data in the dataframes above using best practices for Pc5 waves. We'll be using the systems established in this paper: https://doi.org/10.3389/fspas.2022.877172 \n",
    "\n",
    "The output of this code will be another pandas dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a449c189-69f2-4935-8ef7-609f48588f62",
   "metadata": {},
   "source": [
    "### Convert station coordinates to spatial coordinates in audio environment\n",
    "There are multiple ways that we can do this. One way is to put the listener at the center of the Earth and situate the stations around them. \n",
    "\n",
    "However we set it up, there are two things we should ensure:\n",
    "- The audio coordinates should be a direct transform from the physical coordinates of the stations;\n",
    "- The audio coordinates for satellites should be produced as pandas dataframes, so that they move over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa0a3e5-988e-4c34-a9b3-d74c1befea9e",
   "metadata": {},
   "source": [
    "## Binauralize audio\n",
    "Next, we'll use spaudiopy (https://github.com/chris-hld/spaudiopy) to put the audio we computed at the coordinates we computed, and produce an audio file for it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xonsh",
   "language": "xonsh",
   "name": "xonsh"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".xsh",
   "mimetype": "text/x-sh",
   "name": "xonsh",
   "pygments_lexer": "xonsh",
   "version": "0.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
